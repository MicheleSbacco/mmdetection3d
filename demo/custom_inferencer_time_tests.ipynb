{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Time Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## Initialize ##################################################\n",
    "\n",
    "# Add the new path\n",
    "import sys\n",
    "new_path2 = \"/home/michele/code/michele_mmdet3d/\"\n",
    "if not new_path2 in sys.path:\n",
    "    sys.path.insert(1, new_path2)\n",
    "\n",
    "# TODO:\n",
    "#   - Try to create the loader/packer/preprocessor with the config file, and not manually inserting the parameters\n",
    "#   - Need to implement all the strange categories that Riccardo did?\n",
    "\n",
    "# Main variables\n",
    "    # Boolean to print inputs/outputs of each stage\n",
    "wanna_print_in_out = False\n",
    "    # Home directory within ADE\n",
    "home_dir = '/home/michele/code/'\n",
    "    # Relative path from \"home_dir\" to the .bin files\n",
    "path_from_home_to_bin_files = \"michele_mmdet3d/data/minerva_polimove/training/velodyne\"\n",
    "    # Path to the \".txt\" file in \"ImageSets\", containing the list of validation files\n",
    "val_list_txt_file = \"/home/michele/code/michele_mmdet3d/data/minerva_polimove/ImageSets/val.txt\"\n",
    "\n",
    "\n",
    "\n",
    "############################################# Time-related variables #############################################\n",
    "import time\n",
    "import torch\n",
    "\n",
    "delta_preprocessing = []\n",
    "delta_inference = []\n",
    "delta_postprocessing = []\n",
    "\n",
    "\n",
    "\n",
    "################################################ Create the model ################################################\n",
    "from mmdeploy.apis.inference import get_model\n",
    "\n",
    "# Build the model with the built-in function\n",
    "model = get_model(\n",
    "    model_cfg= home_dir + 'michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py',\n",
    "    deploy_cfg= home_dir + 'mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4.py',\n",
    "    backend_files= [ home_dir + 'mmdeploy/mmdeploy_models/minerva_pointpillars/end2end.engine' ],\n",
    "    img= home_dir + 'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235584511788288.bin',\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Build the additional BBoxHead (for PointPillars)\n",
    "from mmengine.registry import MODELS\n",
    "bbox_head = MODELS.build(model.model_cfg.model['bbox_head'])\n",
    "\n",
    "\n",
    "\n",
    "############################################### Automatic configs ###############################################\n",
    "\n",
    "config_dictionary = {}\n",
    "\n",
    "# For the loader\n",
    "config_dictionary['LoadPointsFromFile'] = {\n",
    "    'coord_type': model.model_cfg.val_dataloader.dataset.pipeline[0].coord_type,\n",
    "    'load_dim': model.model_cfg.val_dataloader.dataset.pipeline[0].load_dim,\n",
    "    'use_dim': model.model_cfg.val_dataloader.dataset.pipeline[0].use_dim\n",
    "}\n",
    "\n",
    "# For the packer\n",
    "#  |\n",
    "#  |--------------> NOTE: Not used because the only field is \n",
    "#  |                \"keys\" and we have it DIFFERENT\n",
    "#  |\n",
    "config_dictionary['Pack3DDetInputs'] = {}\n",
    "\n",
    "# For the Det3DDataPreprocessor\n",
    "config_dictionary['Det3DDataPreprocessor'] = {\n",
    "    'voxel': model.model_cfg.model.data_preprocessor.voxel,\n",
    "    'voxel_layer': dict(\n",
    "        max_num_points = model.model_cfg.model.data_preprocessor.voxel_layer.max_num_points,\n",
    "        max_voxels = model.model_cfg.model.data_preprocessor.voxel_layer.max_voxels,\n",
    "        point_cloud_range = model.model_cfg.model.data_preprocessor.voxel_layer.point_cloud_range,\n",
    "        voxel_size = model.model_cfg.model.data_preprocessor.voxel_layer.voxel_size\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "############################################ Basic type of input metas ############################################\n",
    "\n",
    "# NOTE:\n",
    "#   - Necessary to use the bbox_head with no errors\n",
    "#   - Supposes that no transformations are applied to the pointcloud\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from mmdet3d.structures.bbox_3d import Box3DMode, LiDARInstance3DBoxes\n",
    "\n",
    "# Recreating the variable with the correct types\n",
    "metas_base_variable = {\n",
    "    'box_mode_3d': Box3DMode.LIDAR,  # Enum type\n",
    "    'lidar_path': '',\n",
    "    'pcd_vertical_flip': False,\n",
    "    'pcd_rotation_angle': 0.0,\n",
    "    'pcd_rotation': torch.tensor([[1., 0., 0.],\n",
    "                                  [-0., 1., 0.],\n",
    "                                  [0., 0., 1.]]),\n",
    "    'transformation_3d_flow': ['R', 'S', 'T'],\n",
    "    'pcd_scale_factor': 1.0,\n",
    "    'box_type_3d': LiDARInstance3DBoxes,\n",
    "    'pcd_trans': np.array([0., 0., 0.]),\n",
    "    'pcd_horizontal_flip': False,\n",
    "    'flip': False,\n",
    "    'axis_align_matrix': np.array([[1., 0., 0., 0.],\n",
    "                                   [0., 1., 0., 0.],\n",
    "                                   [0., 0., 1., 0.],\n",
    "                                   [0., 0., 0., 1.]])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "############################################ Define testing configuration ############################################\n",
    "\n",
    "# NOTE:\n",
    "#   - Necessary to use the bbox_head with no errors\n",
    "#   - Can be modified as wanted\n",
    "\n",
    "from mmengine.config.config import ConfigDict\n",
    "\n",
    "test_cfg = ConfigDict(\n",
    "    max_num = 10, \n",
    "    min_bbox_size = 0, \n",
    "    nms_across_levels = False, \n",
    "    nms_pre = 10, \n",
    "    nms_thr = 0.01, \n",
    "    score_thr = 0.3, \n",
    "    use_rotate_nms = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Very original input ###############################################\n",
    "\n",
    "# Read the names of the validation files from the \".txt\" file in \"ImageSets\"\n",
    "with open(val_list_txt_file, 'r') as file:\n",
    "    val_file_names = [line.strip()+\".bin\" for line in file]\n",
    "\n",
    "# Create the inputs\n",
    "#   - List of strings\n",
    "#   - Each string is the ABSOLUTE path to the \".bin\" file\n",
    "inputs = []\n",
    "for file_name in val_file_names:\n",
    "    inputs.append(home_dir+path_from_home_to_bin_files+\"/\"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### LoadPointsFromFile ###############################################\n",
    "\n",
    "from mmdet3d.datasets.transforms.loading import LoadPointsFromFile\n",
    "\n",
    "# Initialize the loader\n",
    "loader = LoadPointsFromFile(\n",
    "    coord_type=config_dictionary['LoadPointsFromFile']['coord_type'],\n",
    "    load_dim=config_dictionary['LoadPointsFromFile']['load_dim'],\n",
    "    use_dim=config_dictionary['LoadPointsFromFile']['use_dim']\n",
    ")\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out:\n",
    "    print(\"\\nLoadPointsFromFile input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# For cycle to also handle lists of inputs\n",
    "for i in range(len(inputs)):\n",
    "    \n",
    "    # Prepare the string input for the loader (needs two dictionaries, one nested into the other)\n",
    "    inputs[i] = dict(\n",
    "        lidar_points=dict(\n",
    "            lidar_path=inputs[i]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Actual modification of the dictionary\n",
    "    loader(inputs[i])\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nLoadPointsFromFile output:\")\n",
    "    for element in inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Pack3DDetInputs ###############################################\n",
    "\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "\n",
    "# Initialize the packer\n",
    "packer = Pack3DDetInputs(keys='points')\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nPack3DDetInputs input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# For cycle to also handle lists of inputs\n",
    "for i in range(len(inputs)):\n",
    "    \n",
    "    # Actual modification of the dictionary\n",
    "    packer(inputs)\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nPack3DDetInputs output:\")\n",
    "    for element in inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Det3DDataPreprocessor ###############################################\n",
    "\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import Det3DDataPreprocessor\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = Det3DDataPreprocessor(\n",
    "    voxel=config_dictionary['Det3DDataPreprocessor']['voxel'],\n",
    "    voxel_layer=config_dictionary['Det3DDataPreprocessor']['voxel_layer']\n",
    ")\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nDet3DDataPreprocessor input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# Create the list with the final inputs\n",
    "final_inputs = []\n",
    "for i in range(len(inputs)):    \n",
    "    # Create a temporary dictionary to be passed to the preprocessor (in the right format)\n",
    "    temp = dict(\n",
    "        inputs=dict(\n",
    "            points=[inputs[i]['points']]    ## Must be into a list, otherwise error\n",
    "        )\n",
    "    )\n",
    "    # Take out the result of the Det3DDataPreprocessor, and also compute the time\n",
    "    start_preprocessing = time.time()\n",
    "    final_inputs.append(\n",
    "        preprocessor(temp)\n",
    "    )\n",
    "    torch.cuda.synchronize()\n",
    "    end_preprocessing = time.time()\n",
    "    # Append the time to the right list\n",
    "    delta_preprocessing.append(end_preprocessing-start_preprocessing)\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nDet3DDataPreprocessor output:\")\n",
    "    for element in final_inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# Inference #################################################\n",
    "\n",
    "raw_results=[]\n",
    "for element in final_inputs:\n",
    "    # Take out the result of the inferencer, and also compute the time\n",
    "    start_inference = time.time()\n",
    "    raw_results.append(\n",
    "        model(element['inputs'], mode='tensor')\n",
    "    )\n",
    "    torch.cuda.synchronize()\n",
    "    end_inference = time.time()\n",
    "    # Append the time to the right list\n",
    "    delta_inference.append(end_inference-start_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## Post_processing ##############################################\n",
    "\n",
    "predictions=[]\n",
    "for element in raw_results:\n",
    "    # Take out the prediction, and also compute the time\n",
    "    start_postprocessing = time.time()\n",
    "    predictions.append(\n",
    "        bbox_head.predict_by_feat(\n",
    "            cls_scores = element['cls_score'],\n",
    "            bbox_preds = element['bbox_pred'],\n",
    "            dir_cls_preds = element['dir_cls_pred'],\n",
    "            batch_input_metas = [metas_base_variable],\n",
    "            cfg = test_cfg\n",
    "        )\n",
    "    )\n",
    "    torch.cuda.synchronize()\n",
    "    end_postprocessing = time.time()\n",
    "    # Append the time to the right list\n",
    "    delta_postprocessing.append(end_postprocessing-start_postprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#                                            PLOTTING OF FREQUENCY                                              #\n",
    "#################################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_frequency_plot(values, title = \"Frequency Plot\"):\n",
    "    # Calculating the average value of the given list\n",
    "    average_value = sum(values) / len(values)\n",
    "\n",
    "    # Plotting the frequency plot with a vertical red line for the average value\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(values, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.axvline(average_value, color='red', linestyle='dashed', linewidth=2, label=f'Average: {average_value:.4f}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# delta_inference = []\n",
    "# for i in range(len(delta_voxel)):\n",
    "#     delta_inference.append(delta_voxel[i] + delta_middle[i] + delta_backbone[i] + delta_neck[i])\n",
    "print_frequency_plot(delta_post, \"Postprocessing time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
