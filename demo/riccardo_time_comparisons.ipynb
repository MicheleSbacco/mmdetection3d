{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add the new path\n",
    "import sys\n",
    "new_path2 = \"/home/michele/code/michele_mmdet3d/\"\n",
    "if not new_path2 in sys.path:\n",
    "    sys.path.insert(1, new_path2)\n",
    "\n",
    "# from mmdet3d.apis import LidarDet3DInferencer\n",
    "# import os\n",
    "# import torch\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import time\n",
    "# from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "#                                                 LoadPointsFromFile)\n",
    "# from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "#     Det3DDataPreprocessor\n",
    "# import onnxruntime as ort\n",
    "# from mmdet3d.datasets.transforms.formating import Pack3DDetInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                 LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "import os \n",
    "\n",
    "pcl = '/home/michele/code/michele_mmdet3d/data/minerva_polimove/training/velodyne'\n",
    "inputs = dict(points=pcl)\n",
    "\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = [inputs[\"points\"] + \"/\" + s for s in os.listdir(inputs[\"points\"])]\n",
    "    \n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1)\n",
    "print()\n",
    "print(prep_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencer (half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "s = time.time()\n",
    "\n",
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1) # Preprocess\n",
    "res = model(prep_input[\"inputs\"],prep_input[\"data_samples\"], mode=\"tensor\") # Forward\n",
    "preds  = model.bbox_head.predict_by_feat(*res) # Postprocess\n",
    "\n",
    "print(\"Time: {} ms\".format((time.time()-s)*1000))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_res = inferencer(inputs, show=False,pred_score_thr=0.3, batch_size=4)\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Manually the tensor to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.dense_heads.anchor3d_head import Anchor3DHead\n",
    "\n",
    "# bbox_head=dict(\n",
    "#     type='Anchor3DHead',\n",
    "#     num_classes=3,\n",
    "#     in_channels=384,\n",
    "#     feat_channels=384,\n",
    "#     use_direction_classifier=True,\n",
    "#     assign_per_class=True,\n",
    "#     anchor_generator=dict(\n",
    "#         type='AlignedAnchor3DRangeGenerator',\n",
    "#         ranges=[\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -1.78, 69.12, 39.68, -1.78],\n",
    "#         ],\n",
    "#         sizes=[[0.8, 0.6, 1.73], [1.76, 0.6, 1.73], [3.9, 1.6, 1.56]],\n",
    "#         rotations=[0, 1.57],\n",
    "#         reshape_out=False),\n",
    "#     diff_rad_by_sin=True,\n",
    "#     bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder')\n",
    "# )\n",
    "# model.bbox_head\n",
    "head = Anchor3DHead(\n",
    "    num_classes=1,\n",
    "    in_channels=384,\n",
    "    feat_channels=384,\n",
    "    use_direction_classifier=True,\n",
    "    assign_per_class=True,\n",
    "    anchor_generator=dict(\n",
    "                type='AlignedAnchor3DRangeGenerator',\n",
    "                ranges=[[0, -39.68, -1.78, 69.12, 39.68, -1.78]],\n",
    "                sizes=[[3.9, 1.6, 1.56]],\n",
    "                rotations=[0, 1.57],\n",
    "                reshape_out=True),\n",
    "    diff_rad_by_sin=True,\n",
    "    bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'),\n",
    "    test_cfg=model.test_cfg\n",
    "    )\n",
    "# preds  = head.predict_by_feat(*res)\n",
    "preds  = model.bbox_head.predict_by_feat(*res)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][\"bboxes_3d\"],pred_res[0][\"bboxes_3d\"],inf_res[\"predictions\"][0][\"bboxes_3d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n",
    "pcl_path = \"../data/DonaSet/training/velodyne/\"\n",
    "model_path = \"end2end.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "\n",
    "pcl_path = \"../data/DonaSet/training/velodyne/\"\n",
    "s = time.time()\n",
    "\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "# Evaluate on validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_output = model(inputs,mode=\"tensor\")\n",
    "    print(\"Time: {} ms\".format((time.time()-s)*1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model_path = \"end2end.onnx\"\n",
    "m = onnx.load(onnx_model_path)\n",
    "opset_version = m.opset_import[0].version if m.opset_import else None\n",
    "\n",
    "print(\"ONNX Model Operator Set Version:\", opset_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_version = onnxruntime.__version__\n",
    "print(\"ONNX Runtime Version:\", ort_version)\n",
    "\n",
    "print( onnxruntime.get_device()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "model_path = 'end2end.onnx'\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_sess = ort.InferenceSession(model_path,providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "s05 = time.time()\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "s3 = time.time()\n",
    "\n",
    "print(\"Preprocessing took: {} ms\".format((s05-s0)*1000))\n",
    "print(\"Cpu conv took: {} ms\".format((s1-s05)*1000))\n",
    "print(\"Inference took: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Postprocessing took: {} ms\".format((s3-s2)*1000))\n",
    "print(\"Total: {} ms\".format((s3-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "s05 = time.time()\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "s1 = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, device = \"cpu\")[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=[ 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.apis.inference import get_model\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = [inputs[\"points\"] + \"/\" + s for s in os.listdir(inputs[\"points\"])]\n",
    "    \n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input\n",
    "\n",
    "\n",
    "\n",
    "home_dir = '/home/michele/code/'\n",
    "pcl_path = '/home/michele/code/michele_mmdet3d/data/minerva_polimove/training/velodyne'\n",
    "\n",
    "model_cfg= home_dir + 'michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py'\n",
    "deploy_cfg= home_dir + 'mmdeploy/configs/mmdet/detection/detection_tensorrt_dynamic-320x320-1344x1344.py'\n",
    "backend_files= ['/home/michele/code/mmdeploy/mmdeploy_models/minerva_pointpillars/end2end.engine']\n",
    "img= home_dir + 'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235584511788288.bin'\n",
    "device= 'cuda'\n",
    "\n",
    "tensorrt_model = get_model(\n",
    "    model_cfg= home_dir + 'michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py',\n",
    "    deploy_cfg= home_dir + 'mmdeploy/configs/mmdet/detection/detection_tensorrt_dynamic-320x320-1344x1344.py',\n",
    "    backend_files= ['/home/michele/code/mmdeploy/mmdeploy_models/minerva_pointpillars/end2end.engine'],\n",
    "    img= home_dir + 'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235584511788288.bin',\n",
    "    device= 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False)[\"inputs\"]\n",
    "\n",
    "res = tensorrt_model(inputs, None, mode=\"predict\")\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
