{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Time Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new path\n",
    "import sys\n",
    "new_path2 = \"/home/michele/code/michele_mmdet3d/\"\n",
    "if not new_path2 in sys.path:\n",
    "    sys.path.insert(1, new_path2)\n",
    "\n",
    "# NOTE and TODO:\n",
    "#   - Try to create the loader/packer/preprocessor with the config file, and not manually inserting the parameters\n",
    "#   - The variable \"inputs\" is used as a pointer, because the system uses it like this\n",
    "\n",
    "wanna_print_in_out = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Very original input ###############################################\n",
    "\n",
    "home_dir = '/home/michele/code/'\n",
    "\n",
    "# Inputs: a list of strings (each string is the ABSOLUTE path to the \".bin\" file\n",
    "inputs = [\n",
    "    # home_dir+'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235389267178975.bin',\n",
    "    # home_dir+'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235389968373008.bin',\n",
    "    home_dir+'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723923467966083319.bin'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### LoadPointsFromFile ###############################################\n",
    "\n",
    "from mmdet3d.datasets.transforms.loading import LoadPointsFromFile\n",
    "\n",
    "# Initialize the loader\n",
    "loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out:\n",
    "    print(\"\\nLoadPointsFromFile input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# For cycle to also handle lists of inputs\n",
    "for i in range(len(inputs)):\n",
    "    \n",
    "    # Prepare the string input for the loader (needs two dictionaries, one nested into the other)\n",
    "    inputs[i] = dict(\n",
    "        lidar_points=dict(\n",
    "            lidar_path=inputs[i]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Actual modification of the dictionary\n",
    "    loader(inputs[i])\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nLoadPointsFromFile output:\")\n",
    "    for element in inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Pack3DDetInputs ###############################################\n",
    "\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "\n",
    "# Initialize the packer\n",
    "packer = Pack3DDetInputs(keys='points')\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nPack3DDetInputs input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# For cycle to also handle lists of inputs\n",
    "for i in range(len(inputs)):\n",
    "    \n",
    "    # Actual modification of the dictionary\n",
    "    packer(inputs)\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nPack3DDetInputs output:\")\n",
    "    for element in inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Det3DDataPreprocessor ###############################################\n",
    "\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import Det3DDataPreprocessor\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = Det3DDataPreprocessor(\n",
    "    voxel=True,\n",
    "    voxel_layer=dict(\n",
    "        max_num_points = 32,\n",
    "        max_voxels = (20000,40000,),\n",
    "        point_cloud_range = [-90, -28.8, -2, 166, 28.8, 5,],\n",
    "        voxel_size = [0.16, 0.16, 7,]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print the input to this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nDet3DDataPreprocessor input:\")\n",
    "    for element in inputs:\n",
    "        print(element)\n",
    "\n",
    "# Create the list with the final inputs\n",
    "final_inputs = []\n",
    "for i in range(len(inputs)):    \n",
    "    # Create a temporary dictionary to be passed to the preprocessor (in the right format)\n",
    "    temp = dict(\n",
    "        inputs=dict(\n",
    "            points=[inputs[i]['points']]    ## Must be into a list, otherwise error\n",
    "        )\n",
    "    )\n",
    "    # Append the result to the \"final_inputs\" list\n",
    "    final_inputs.append(preprocessor(temp))\n",
    "\n",
    "# TODO: Add an if for the device type\n",
    "for i in range(len(final_inputs)):\n",
    "    for subkey in final_inputs[i]['inputs']['voxels']:\n",
    "        final_inputs[i]['inputs']['voxels'][subkey] = final_inputs[i]['inputs']['voxels'][subkey].cuda()\n",
    "\n",
    "# Print the output of this stage\n",
    "if wanna_print_in_out: \n",
    "    print(\"\\nDet3DDataPreprocessor output:\")\n",
    "    for element in final_inputs:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/home/michele/code/'\n",
    "\n",
    "\n",
    "\n",
    "# Import mmdeploy from the ROOT FOLDER -------> NOTE: It is not my own repository, it is the one in root (probably modified by Riccardo)\n",
    "from mmdeploy.apis.inference import get_model\n",
    "\n",
    "\n",
    "\n",
    "model = get_model(\n",
    "    model_cfg= home_dir + 'michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py',\n",
    "    deploy_cfg= home_dir + 'mmdeploy/configs/mmdet/detection/detection_tensorrt_dynamic-320x320-1344x1344.py',\n",
    "    backend_files= ['/home/michele/code/mmdeploy/mmdeploy_models/minerva_pointpillars/end2end.engine'],\n",
    "    img= home_dir + 'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235584511788288.bin',\n",
    "    device= 'cuda'\n",
    ")\n",
    "\n",
    "result = model(final_inputs[0]['inputs'], final_inputs[0]['data_samples'], None)\n",
    "\n",
    "# result = model(final_inputs[0], None, mode='predict')\n",
    "\n",
    "# result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n\\n----------------------------------------------------------\")\n",
    "# print(model.model_cfg.model.data_preprocessor)\n",
    "# for key in model.model_cfg.model.data_preprocessor:\n",
    "#     print(f\"\\t{key}:\\n{model.model_cfg.model.data_preprocessor[key]}\")\n",
    "# print(\"\\n\\n----------------------------------------------------------\")\n",
    "# print(model.model_cfg.val_dataloader.dataset.pipeline)\n",
    "# for i, element in enumerate(model.model_cfg.val_dataloader.dataset.pipeline):\n",
    "#     print(f\"\\nElement {i}:\")\n",
    "#     for key in element:\n",
    "#         print(f\"\\t{key}:\\n{element[key]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ############################################# TODO: Comment here #############################################\n",
    "# from mmdeploy.apis.inference import inference_model\n",
    "# home_dir = '/home/michele/code/'\n",
    "# result = inference_model(\n",
    "#     model_cfg= home_dir + 'michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py',\n",
    "#     deploy_cfg= home_dir + 'mmdeploy/configs/mmdet/detection/detection_tensorrt_dynamic-320x320-1344x1344.py',\n",
    "#     backend_files= ['/home/michele/code/mmdeploy/mmdeploy_models/minerva_pointpillars/end2end.engine'],\n",
    "#     img= home_dir + 'michele_mmdet3d/data/minerva_polimove/training/velodyne/1723235584511788288.bin',\n",
    "#     device= 'cuda'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# Line 278 of object_detection_model.py:\n",
    "#     def forward(self,\n",
    "#                 inputs: torch.Tensor,\n",
    "#                 data_samples: List[BaseDataElement],\n",
    "#                 mode: str = 'predict',\n",
    "#                 **kwargs) -> Any:\n",
    "#         \"\"\"The model forward.\n",
    "\n",
    "#         Args:\n",
    "#             inputs (torch.Tensor): The input tensors\n",
    "#             data_samples (List[BaseDataElement]): The data samples.\n",
    "#                 Defaults to None.\n",
    "#             mode (str, optional): forward mode, only support `predict`.\n",
    "\n",
    "#         Returns:\n",
    "#             Any: Model output.\n",
    "#         \"\"\"\n",
    "#         # assert mode == 'predict', 'Deploy model only allow mode==\"predict\".'\n",
    "#         # inputs = inputs.contiguous()\n",
    "#         outputs = self._forward(inputs, data_samples)\n",
    "#         batch_dets, batch_labels = outputs[:2]\n",
    "#         batch_masks = outputs[2] if len(outputs) >= 3 else None\n",
    "#         self.postprocessing_results(batch_dets, batch_labels, batch_masks,\n",
    "#                                     data_samples)\n",
    "#         return data_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
