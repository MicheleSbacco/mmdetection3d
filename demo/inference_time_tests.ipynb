{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Time Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *base.py* file (mmengine) with class BaseModel add **imports** \n",
    "\n",
    "```python\n",
    "        import time\n",
    "        from demo.json_handler import JSONHandler\n",
    "```\n",
    "\n",
    "and **the following** (in test_step):\n",
    "\n",
    "```python\n",
    "        begin = time.time()\n",
    "        data = self.data_preprocessor(data, False)\n",
    "        end = time.time()\n",
    "\n",
    "        out_file = '/home/michele*/code/michele_mmdet3d/data/minerva_polimove/inference_times.json'\n",
    "        handler = JSONHandler(out_file, True)\n",
    "        handler.update_dictionary({'Pre-processing delta_t': (end-begin)})\n",
    "\n",
    "        return self._run_forward(data, mode='predict')  # type: ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#                                      INFERENCE AND SAVE THE DATA                                              #\n",
    "#################################################################################################################\n",
    "\n",
    "# Needed imports\n",
    "import sys\n",
    "from json_handler import JSONHandler\n",
    "import time\n",
    "\n",
    "\n",
    "# Add the new paths separately\n",
    "new_path2 = \"/home/michele/code/michele_mmdet3d/\"\n",
    "if not new_path2 in sys.path:\n",
    "    sys.path.insert(1, new_path2)\n",
    "# Import the fucking wicked class\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "\n",
    "\n",
    "# Initialize the actual inferencer class\n",
    "inferencer = LidarDet3DInferencer(model='/home/michele/code/michele_mmdet3d/configs/minerva/CONDENSED_pointpillars_minerva.py', \n",
    "                                  weights='/home/michele/code/michele_mmdet3d/work_dirs/pointpillars_minerva/epoch_120.pth',\n",
    "                                  show_progress=False)\n",
    "\n",
    "\n",
    "# Read the files in validation list\n",
    "val_list_txt_file = \"/home/michele/code/michele_mmdet3d/data/minerva_polimove/ImageSets/val.txt\"\n",
    "with open(val_list_txt_file, 'r') as file:\n",
    "    val_file_names = [line.strip() for line in file]\n",
    "print(f\"Total validation point_clouds: {len(val_file_names)}\")\n",
    "\n",
    "\n",
    "# Create the list of inputs, suitable for the inferencer\n",
    "inputs = []\n",
    "for i, name in enumerate(val_file_names):\n",
    "    inputs.append(dict(points=(\"/home/michele/code/michele_mmdet3d/data/minerva_polimove/training/velodyne/\"+name+\".bin\")))\n",
    "\n",
    "\n",
    "# Create an instance JSONHandler\n",
    "out_file = '/home/michele/code/michele_mmdet3d/data/minerva_polimove/inference_times.json'\n",
    "handler = JSONHandler(out_file)\n",
    "# Remove the file if already existing\n",
    "handler.reset()\n",
    "# Do the actual inference\n",
    "results = []\n",
    "for i, input in enumerate(inputs):\n",
    "    begin = time.time()\n",
    "    handler.add_dictionary({'Everything start': begin})\n",
    "    results.append(inferencer(input))\n",
    "    end = time.time()\n",
    "    handler.update_dictionary({'Everything end': end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in handler.read_json_file():\n",
    "    print(element)\n",
    "\n",
    "dictionary_list = handler.read_json_file()\n",
    "print(f\"\\nThere are {len(dictionary_list)} elements in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#                                  STUDY OF BASE_MODEL (NOT ACCESSIBLE)                                         #\n",
    "#################################################################################################################\n",
    "\n",
    "start = handler.get_parameter('Everything start')\n",
    "end = handler.get_parameter('Voxel encoder start')\n",
    "estimated_delta = []\n",
    "for i in range(len(start)):\n",
    "    estimated_delta.append( end[i]-start[i] )\n",
    "\n",
    "compute_error = False\n",
    "\n",
    "if compute_error:\n",
    "    actual_delta = handler.get_parameter('Pre-processing delta_t')\n",
    "    error = []\n",
    "    error_abs = []\n",
    "    for i in range(len(actual_delta)):\n",
    "        error.append( actual_delta[i]-estimated_delta[i] )\n",
    "        error_abs.append( abs( actual_delta[i]-estimated_delta[i] ) )\n",
    "\n",
    "av_est_deltaT = sum(estimated_delta)/len(estimated_delta)\n",
    "print(f\"Average value of the estimated delta_t: {av_est_deltaT}\")\n",
    "if compute_error:\n",
    "    print(f\"Average value of the error: {sum(error)/len(error)}\")\n",
    "    av_abs_error = sum(error_abs)/len(error_abs)\n",
    "    print(f\"Average value for the absolute error: {av_abs_error}\")\n",
    "    av_act_deltat = sum(actual_delta)/len(actual_delta)\n",
    "    print(f\"The percentage of error is {av_abs_error/av_est_deltaT*100}. The average actual delta_t is {av_act_deltat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#                                            GENERAL STUDY OF TIME                                              #\n",
    "#################################################################################################################\n",
    "\n",
    "start_everything = handler.get_parameter('Everything start')\n",
    "start_voxel = handler.get_parameter('Voxel encoder start')\n",
    "delta_voxel = handler.get_parameter('Voxel encoder delta_t')\n",
    "delta_middle = handler.get_parameter('Middle encoder delta_t')\n",
    "delta_backbone = handler.get_parameter('Backbone delta_t')\n",
    "delta_neck = handler.get_parameter('Neck delta_t')\n",
    "delta_post = handler.get_parameter('Post-processing delta_t')\n",
    "end_everything = handler.get_parameter('Everything end')\n",
    "handler.reset()\n",
    "\n",
    "# Total time\n",
    "delta_total = []\n",
    "for i in range(len(start_everything)):\n",
    "    delta_total.append(end_everything[i]-start_everything[i])\n",
    "estimated_total = sum(delta_total)/len(delta_total)\n",
    "print(f\"Average total time: {estimated_total*1e3:.2f}ms which would be {1/estimated_total:.2f}Hz!\")\n",
    "# Preprocessing\n",
    "delta_pre = []\n",
    "for i in range(len(start_everything)):\n",
    "    delta_pre.append(start_voxel[i]-start_everything[i])\n",
    "estimated_pre = sum(delta_pre)/len(delta_pre)\n",
    "print(f\"\\tAverage pre-processing time:\\t{estimated_pre*1e3:.2f}ms which means\\t{100*estimated_pre/estimated_total:.2f} over the total. \\\n",
    "      \\n\\t\\tUsually 20% higher than actual value, which would be {estimated_pre*0.8*1e3:.2f}ms\")\n",
    "# Voxel encoder\n",
    "estimated_voxel = sum(delta_voxel)/len(delta_voxel)\n",
    "print(f\"\\tAverage voxel encoder time:\\t{estimated_voxel*1e3:.2f}ms which means\\t{100*estimated_voxel/estimated_total:.2f} over the total.\")\n",
    "# Middle encoder\n",
    "estimated_middle = sum(delta_middle)/len(delta_middle)\n",
    "print(f\"\\tAverage middle encoder time:\\t{estimated_middle*1e3:.2f}ms which means\\t{100*estimated_middle/estimated_total:.2f} over the total.\")\n",
    "# Backbone\n",
    "estimated_backbone = sum(delta_backbone)/len(delta_backbone)\n",
    "print(f\"\\tAverage backbone time:\\t\\t{estimated_backbone*1e3:.2f}ms which means\\t{100*estimated_backbone/estimated_total:.2f} over the total.\")\n",
    "# Neck\n",
    "estimated_neck = sum(delta_neck)/len(delta_neck)\n",
    "print(f\"\\tAverage neck time:\\t\\t{estimated_neck*1e3:.2f}ms which means\\t{100*estimated_neck/estimated_total:.2f} over the total.\")\n",
    "# Post-processing\n",
    "estimated_post = sum(delta_post)/len(delta_post)\n",
    "print(f\"\\tAverage post-processing time:\\t{estimated_post*1e3:.2f}ms which means\\t{100*estimated_post/estimated_total:.2f} over the total.\")\n",
    "# Final comment\n",
    "sum_all_0 = estimated_pre + estimated_voxel + estimated_middle + estimated_backbone + estimated_neck + estimated_post\n",
    "sum_all_1 = estimated_pre*0.8 + estimated_voxel + estimated_middle + estimated_backbone + estimated_neck + estimated_post\n",
    "sum_inference = estimated_voxel + estimated_middle + estimated_backbone + estimated_neck\n",
    "print(f\"\\nBy summing all the \\\"sub-components\\\" we get:\\\n",
    "      \\n\\tA total time of {sum_all_0*1e3:.2f}ms ({1/sum_all_0:.2f}Hz) which means\\t{100*sum_all_0/estimated_total:.2f}% over the total of\\t{estimated_total*1e3:.2f}ms\\\n",
    "      \\nand by considering the \\\"real\\\" value for the preprocessing (20% less), we get:\\\n",
    "      \\n\\tA total time of {sum_all_1*1e3:.2f}ms ({1/sum_all_1:.2f}Hz) which means\\t{100*sum_all_1/estimated_total:.2f}% over the total of\\t{estimated_total*1e3:.2f}ms\\\n",
    "      \\nwhile the inference (from voxel encoder to neck) accounts for:\\\n",
    "      \\n\\tA total time of {sum_inference*1e3:.2f}ms which means\\t\\t{100*sum_inference/estimated_total:.2f}% over the total of\\t\\t{estimated_total*1e3:.2f}ms\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c343fece975dd89087e8c2194dd4d3db28d7000f1b32ed9ed9d584dd54dbbe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
